{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import pandas as pd\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import webcolors\n",
    "from functools import reduce\n",
    "\n",
    "root='../input/data/' # 재활용 데이터 경로\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils import class_colormap, label_to_color_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_trash_label_colormap():\n",
    "    \"\"\"Creates a label colormap used in Trash segmentation.\n",
    "    Returns:\n",
    "        A colormap for visualizing segmentation results.\n",
    "    \"\"\"\n",
    "    colormap = np.zeros((11, 3), dtype=np.uint8)\n",
    "    for inex, (r, g, b) in enumerate(class_colormap):\n",
    "        colormap[inex] = [r, g, b]\n",
    "    \n",
    "    return colormap\n",
    "\n",
    "\n",
    "def visualization(num_examples, index):\n",
    "    category_and_rgb = [[category, (r,g,b)] for idx, (category, r, g, b) in enumerate(class_colormap.values)]\n",
    "    legend_elements = [Patch(facecolor=webcolors.rgb_to_hex(rgb), \n",
    "                             edgecolor=webcolors.rgb_to_hex(rgb), \n",
    "                             label=category) for category, rgb in category_and_rgb]\n",
    "    \n",
    "    images = []\n",
    "    submission = pd.read_csv(submission_path, index_col=None)[index:index + num_examples]\n",
    "    image_ids=submission[\"image_id\"].values\n",
    "    masks = submission[\"PredictionString\"].values\n",
    "\n",
    "    # image load\n",
    "    for i in range(num_examples):\n",
    "        image_id = image_ids[i]\n",
    "        image = cv2.imread(os.path.join(root, image_id))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        images.append(image)\n",
    "\n",
    "    # mask load\n",
    "    for m in range(num_examples):\n",
    "        # mask = masks[i].split()\n",
    "        mask = list(map(int, masks[m].split()))\n",
    "        mask = np.array(mask)\n",
    "        mask = np.reshape(mask, (-1, 256))\n",
    "        masks[m] = mask\n",
    "        \n",
    "    # plt 생성\n",
    "    fig, ax = plt.subplots(nrows=num_examples, ncols=2, figsize=(10, 4*num_examples), constrained_layout=True)\n",
    "    \n",
    "    for row_num in range(num_examples):\n",
    "        \n",
    "        # Original Image\n",
    "        ax[row_num][0].imshow(images[row_num])\n",
    "        ax[row_num][0].set_title(f\"Orignal Image : {image_ids[row_num]}\")\n",
    "        \n",
    "        # Pred Mask\n",
    "        ax[row_num][1].imshow(label_to_color_image(masks[row_num]))\n",
    "        ax[row_num][1].set_title(f\"Pred Mask : {image_ids[row_num]}\")\n",
    "        ax[row_num][1].legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmix 3 14 1 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = '/opt/ml/segmentation/semantic-segmentation-level2-cv-06/output/OCRNet_augmix_3_14_1_1_ranCrop_horiz_colJit.csv'\n",
    "visualization(5,350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmix 3 7 1 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = '/opt/ml/segmentation/semantic-segmentation-level2-cv-06/output/OCRNet_augmix_3_7_1_1_epoch_30.csv'\n",
    "visualization(5,350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmix 3 14 1 1 (+ a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = '/opt/ml/segmentation/semantic-segmentation-level2-cv-06/output/OCRNet_augmix_3_14_1_1_ranCrop_horiz_colJit.csv'\n",
    "visualization(5,250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCNResnet50\n",
    "* 디테일한 부분 비교적 잘 잡음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = '/opt/ml/segmentation/semantic-segmentation-level2-cv-06/output/FCNRes50_mIoU_best.csv'\n",
    "visualization(5,250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCRNet\n",
    "* 영역을 많이 잡아내는 듯\n",
    "* 디테일한 부분도 다른 모델보다는 잘 잡음\n",
    "* 스티로폼 잘 잡아냄\n",
    "* Clothing 이상한 거에 예측함 -> 모든 모델이 그러함\n",
    "* 짤려서 예측한 마스크가 많음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = '/opt/ml/segmentation/semantic-segmentation-level2-cv-06/output/OCRNet_mIoU_best.csv'\n",
    "visualization(5,250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficientnetb0-unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = '/opt/ml/segmentation/semantic-segmentation-level2-cv-06/output/efficientnetb0_unet_best_model.csv'\n",
    "visualization(5,250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mobilenetV2-unet\n",
    "* 클래스 예측 정확도 떨어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = '/opt/ml/segmentation/semantic-segmentation-level2-cv-06/output/mobilenetV2_unet_best_model.csv'\n",
    "visualization(5,250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeplabv3-resnet101\n",
    "* 디테일한 부분 캐치에 강점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = '/opt/ml/segmentation/semantic-segmentation-level2-cv-06/output/deeplabv3_resnet101_best_model(pretrained).csv'\n",
    "visualization(5,250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeplabv3 res101 sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = '/opt/ml/segmentation/semantic-segmentation-level2-cv-06/output/DeeplabV3_res101_sort.csv'\n",
    "visualization(5,250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d36e052b391be8c28b05838ade06426769a29575d5fe21a7bc69c7dec0c04c06"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('segmentation': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import albumentations\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "from albumentations.core.transforms_interface import DualTransform, DualTransformCustom\n",
    "from albumentations.augmentations import functional as F\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import label_accuracy_score, add_hist, class_colormap, label_to_color_image\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib.patches import Patch\n",
    "import webcolors\n",
    "\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_path = '/opt/ml/segmentation/semantic-segmentation-level2-cv-06/input/data/'\n",
    "category_names = ['Background', 'General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',\n",
    "                  'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing']\n",
    "\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id'] == classID:\n",
    "            return cats[i]['name']\n",
    "    return \"None\"\n",
    "\n",
    "\n",
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\"\n",
    "    coco format\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, mode='train', transform=None):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.coco = COCO(data_dir)\n",
    "\n",
    "        # Load the categories in a variable\n",
    "        self.cat_ids = self.coco.getCatIds()\n",
    "        self.cats = self.coco.loadCats(self.cat_ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # dataset이 index되어 list처럼 동작\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "\n",
    "        # cv2를 활용하여 image 불러오기\n",
    "        images = cv2.imread(os.path.join(dataset_path, image_infos['file_name']))\n",
    "        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        images /= 255.0\n",
    "\n",
    "        if (self.mode in ('train', 'val')):\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            # masks : size가 (height x width)인 2D\n",
    "            # 각각의 pixel 값에는 \"category id\" 할당\n",
    "            # Background = 0\n",
    "            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "\n",
    "            # General trash = 1, ... , Clothing = 10\n",
    "            # anns = sorted(anns, key=lambda idx: len(idx['segmentation'][0]), reverse=True)\n",
    "            anns = sorted(anns, key=lambda idx : idx['area'], reverse=True)\n",
    "            \n",
    "            for i in range(len(anns)):\n",
    "                # className = get_classname(anns[i]['category_id'], self.cats)\n",
    "                # pixel_value = category_names.index(className)\n",
    "                # masks[self.coco.annToMask(anns[i])==1] = pixel_value\n",
    "                masks[self.coco.annToMask(anns[i])==1] = anns[i]['category_id']\n",
    "            masks = masks.astype(np.int8)\n",
    "\n",
    "            # [기존] transform -> albumentations\n",
    "            # if self.transform is not None:\n",
    "            #     transformed = self.transform(image=images, mask=masks)\n",
    "            #     images = transformed[\"image\"]\n",
    "            #     masks = transformed[\"mask\"]\n",
    "\n",
    "\n",
    "            # [변경] transform -> albumentations\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(imageAndMask=[images, masks])\n",
    "                images, masks = transformed[\"imageAndMask\"]\n",
    "            images = (torch.from_numpy(images)).permute([2,0,1])\n",
    "            masks = torch.from_numpy(masks)\n",
    "\n",
    "            return images, masks, image_infos\n",
    "        elif self.mode == 'test':\n",
    "            # transform -> albumentations\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "            return images, image_infos\n",
    "        else:\n",
    "            raise RuntimeError(\"CustomDataLoader mode error\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.coco.getImgIds())\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mask도 같이 Augment1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def int_parameter(level, maxval):\n",
    "    \"\"\"Helper function to scale `val` between 0 and maxval .\n",
    "    Args:\n",
    "    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
    "    maxval: Maximum value that the operation can have. This will be scaled to\n",
    "      level/PARAMETER_MAX.\n",
    "    Returns:\n",
    "    An int that results from scaling `maxval` according to `level`.\n",
    "    \"\"\"\n",
    "    return int(level * maxval / 10)\n",
    "\n",
    "\n",
    "def float_parameter(level, maxval):\n",
    "    \"\"\"Helper function to scale `val` between 0 and maxval.\n",
    "    Args:\n",
    "    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
    "    maxval: Maximum value that the operation can have. This will be scaled to\n",
    "      level/PARAMETER_MAX.\n",
    "    Returns:\n",
    "    A float that results from scaling `maxval` according to `level`.\n",
    "    \"\"\"\n",
    "    return float(level) * maxval / 10.\n",
    "\n",
    "\n",
    "def sample_level(n):\n",
    "    return np.random.uniform(low=0.1, high=n)\n",
    "\n",
    "\n",
    "def autocontrast(pil_img, pil_mask, _):\n",
    "    return ImageOps.autocontrast(pil_img), pil_mask\n",
    "\n",
    "\n",
    "def equalize(pil_img, pil_mask, _):\n",
    "    return ImageOps.equalize(pil_img), pil_mask\n",
    "\n",
    "\n",
    "def posterize(pil_img, pil_mask, level):\n",
    "    level = int_parameter(sample_level(level), 4)\n",
    "    return ImageOps.posterize(pil_img, 4 - level), pil_mask\n",
    "\n",
    "\n",
    "def rotate(pil_img, pil_mask, level):\n",
    "    degrees = int_parameter(sample_level(level), 30)\n",
    "    if np.random.uniform() > 0.5:\n",
    "        degrees = -degrees\n",
    "    return pil_img.rotate(degrees + 30, resample=Image.BILINEAR), pil_mask.rotate(degrees + 30, resample=Image.BILINEAR)\n",
    "\n",
    "\n",
    "def solarize(pil_img, pil_mask, level):\n",
    "    level = int_parameter(sample_level(level), 256)\n",
    "    return ImageOps.solarize(pil_img, 256 - level),  pil_mask\n",
    "\n",
    "\n",
    "def shear_x(pil_img, pil_mask, level):\n",
    "    level = float_parameter(sample_level(level), 0.3)\n",
    "    if np.random.uniform() > 0.5:\n",
    "        level = -level\n",
    "    return pil_img.transform(pil_img.size,Image.AFFINE, (1, level, 0, 0, 1, 0), resample=Image.BILINEAR), \\\n",
    "           pil_mask.transform(pil_mask.size, Image.AFFINE, (1, level, 0, 0, 1, 0), resample=Image.BILINEAR)\n",
    "                           \n",
    "\n",
    "\n",
    "def shear_y(pil_img, pil_mask, level):\n",
    "    level = float_parameter(sample_level(level), 0.3)\n",
    "    if np.random.uniform() > 0.5:\n",
    "        level = -level\n",
    "    return pil_img.transform(pil_img.size, Image.AFFINE, (1, 0, 0, level, 1, 0), resample=Image.BILINEAR), \\\n",
    "           pil_mask.transform(pil_mask.size, Image.AFFINE, (1, 0, 0, level, 1, 0), resample=Image.BILINEAR),\n",
    "\n",
    "\n",
    "def translate_x(pil_img, pil_mask, level):\n",
    "    level = int_parameter(sample_level(level), pil_img.size[0] / 3)\n",
    "    if np.random.random() > 0.5:\n",
    "        level = -level\n",
    "    return pil_img.transform(pil_img.size, Image.AFFINE, (1, 0, level, 0, 1, 0), resample=Image.BILINEAR), \\\n",
    "           pil_mask.transform(pil_mask.size, Image.AFFINE, (1, 0, level, 0, 1, 0), resample=Image.BILINEAR)\n",
    "\n",
    "\n",
    "def translate_y(pil_img, pil_mask, level):\n",
    "    level = int_parameter(sample_level(level), pil_img.size[0] / 3)\n",
    "    if np.random.random() > 0.5:\n",
    "        level = -level\n",
    "    return pil_img.transform(pil_img.size,Image.AFFINE, (1, 0, 0, 0, 1, level),resample=Image.BILINEAR), \\\n",
    "          pil_mask.transform(pil_mask.size,Image.AFFINE, (1, 0, 0, 0, 1, level),resample=Image.BILINEAR)\n",
    "\n",
    "\n",
    "# operation that overlaps with ImageNet-C's test set\n",
    "def color(pil_img, pil_mask, level):\n",
    "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
    "    return ImageEnhance.Color(pil_img).enhance(level), pil_mask\n",
    "\n",
    "\n",
    "# operation that overlaps with ImageNet-C's test set\n",
    "def contrast(pil_img, pil_mask, level):\n",
    "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
    "    return ImageEnhance.Contrast(pil_img).enhance(level), pil_mask\n",
    "\n",
    "\n",
    "# operation that overlaps with ImageNet-C's test set\n",
    "def brightness(pil_img, pil_mask, level):\n",
    "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
    "    return ImageEnhance.Brightness(pil_img).enhance(level), pil_mask\n",
    "\n",
    "\n",
    "# operation that overlaps with ImageNet-C's test set\n",
    "def sharpness(pil_img, pil_mask, level):\n",
    "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
    "    return ImageEnhance.Sharpness(pil_img).enhance(level), pil_mask\n",
    "\n",
    "\n",
    "# augmentations = [\n",
    "#     autocontrast, \n",
    "#     equalize, \n",
    "#     posterize, rotate, \n",
    "#     solarize, \n",
    "#     shear_x, shear_y,\n",
    "#     translate_x, translate_y\n",
    "# ]\n",
    "\n",
    "augmentations_all = [\n",
    "    autocontrast, equalize, posterize, \n",
    "    rotate, \n",
    "    solarize, \n",
    "    shear_x, shear_y,\n",
    "    translate_x, translate_y, \n",
    "    color, contrast, \n",
    "    brightness, sharpness\n",
    "]\n",
    "\n",
    "def normalize(image):\n",
    "    \"\"\"Normalize input image channel-wise to zero mean and unit variance.\"\"\"\n",
    "    return image - 127\n",
    "\n",
    "def apply_op(image, mask, op, severity):\n",
    "    #   image = np.clip(image, 0, 255)\n",
    "    image = image * 255\n",
    "    image = image.astype(np.uint8)\n",
    "\n",
    "    pil_img = Image.fromarray(image)  # Convert to PIL.Image\n",
    "    pil_mask = Image.fromarray(mask)  # Convert to PIL.Image\n",
    "    \n",
    "    pil_img, pil_mask = op(pil_img, pil_mask, severity)\n",
    "    return np.asarray(pil_img), np.asarray(pil_mask)\n",
    "\n",
    "def augment_and_mix(image, severity=3, width=3, depth=-1, alpha=1., mask=None):\n",
    "    \"\"\"Perform AugMix augmentations and compute mixture.\n",
    "    Args:\n",
    "    image: Raw input image as float32 np.ndarray of shape (h, w, c)\n",
    "    severity: Severity of underlying augmentation operators (between 1 to 10).\n",
    "    width: Width of augmentation chain\n",
    "    depth: Depth of augmentation chain. -1 enables stochastic depth uniformly\n",
    "      from [1, 3]\n",
    "    alpha: Probability coefficient for Beta and Dirichlet distributions.\n",
    "    Returns:\n",
    "    mixed: Augmented and mixed image.\n",
    "    \"\"\"\n",
    "    ws = np.float32(\n",
    "      np.random.dirichlet([alpha] * width))\n",
    "    m = np.float32(np.random.beta(alpha, alpha))\n",
    "\n",
    "    mix = np.zeros_like(image).astype(np.float32)\n",
    "    for i in range(width):\n",
    "        image_aug = image.copy()\n",
    "        mask_aug = mask.copy()\n",
    "        depth = depth if depth > 0 else np.random.randint(1, 4)\n",
    "        for _ in range(depth):\n",
    "            op = np.random.choice(augmentations_all)\n",
    "            image_aug, mask_aug = apply_op(image_aug, mask_aug, op, severity)\n",
    "        # Preprocessing commutes since all coefficients are convex\n",
    "        mix += ws[i] * image_aug\n",
    "#         mix += ws[i] * normalize(image_aug)\n",
    "\n",
    "    mixed = m * (image * 255) + (1 - m) * mix\n",
    "#     mixed = (1 - m) * normalize(image) + m * mix\n",
    "    mixed /= 255\n",
    "\n",
    "    return mixed, mask_aug\n",
    "\n",
    "\n",
    "class RandomAugMix(DualTransformCustom):\n",
    "\n",
    "    def __init__(self, severity=3, width=3, depth=-1, alpha=1., always_apply=False, p=0.5):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.severity = severity\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def apply(self, image, **params):\n",
    "        image, mask = image\n",
    "        image, mask = augment_and_mix(\n",
    "            image,\n",
    "            self.severity,\n",
    "            self.width,\n",
    "            self.depth,\n",
    "            self.alpha,\n",
    "            mask\n",
    "        )\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mask는 놔두고 image만 augment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def int_parameter(level, maxval):\n",
    "#     \"\"\"Helper function to scale `val` between 0 and maxval .\n",
    "#     Args:\n",
    "#     level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
    "#     maxval: Maximum value that the operation can have. This will be scaled to\n",
    "#       level/PARAMETER_MAX.\n",
    "#     Returns:\n",
    "#     An int that results from scaling `maxval` according to `level`.\n",
    "#     \"\"\"\n",
    "#     return int(level * maxval / 10)\n",
    "\n",
    "\n",
    "# def float_parameter(level, maxval):\n",
    "#     \"\"\"Helper function to scale `val` between 0 and maxval.\n",
    "#     Args:\n",
    "#     level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
    "#     maxval: Maximum value that the operation can have. This will be scaled to\n",
    "#       level/PARAMETER_MAX.\n",
    "#     Returns:\n",
    "#     A float that results from scaling `maxval` according to `level`.\n",
    "#     \"\"\"\n",
    "#     return float(level) * maxval / 10.\n",
    "\n",
    "\n",
    "# def sample_level(n):\n",
    "#     return np.random.uniform(low=0.1, high=n)\n",
    "\n",
    "\n",
    "# def autocontrast(pil_img, _):\n",
    "#     return ImageOps.autocontrast(pil_img)\n",
    "\n",
    "\n",
    "# def equalize(pil_img, _):\n",
    "#     return ImageOps.equalize(pil_img)\n",
    "\n",
    "\n",
    "# def posterize(pil_img, level):\n",
    "#     level = int_parameter(sample_level(level), 4)\n",
    "#     return ImageOps.posterize(pil_img, 4 - level)\n",
    "\n",
    "\n",
    "# def rotate(pil_img, level):\n",
    "#     degrees = int_parameter(sample_level(level), 30)\n",
    "#     if np.random.uniform() > 0.5:\n",
    "#         degrees = -degrees\n",
    "#     return pil_img.rotate(degrees, resample=Image.BILINEAR)\n",
    "\n",
    "\n",
    "# def solarize(pil_img, level):\n",
    "#     level = int_parameter(sample_level(level), 256)\n",
    "#     return ImageOps.solarize(pil_img, 256 - level)\n",
    "\n",
    "\n",
    "# def shear_x(pil_img, level):\n",
    "#     level = float_parameter(sample_level(level), 0.3)\n",
    "#     if np.random.uniform() > 0.5:\n",
    "#         level = -level\n",
    "#     return pil_img.transform(pil_img.size,\n",
    "#                            Image.AFFINE, (1, level, 0, 0, 1, 0),\n",
    "#                            resample=Image.BILINEAR)\n",
    "\n",
    "\n",
    "# def shear_y(pil_img, level):\n",
    "#     level = float_parameter(sample_level(level), 0.3)\n",
    "#     if np.random.uniform() > 0.5:\n",
    "#         level = -level\n",
    "#     return pil_img.transform(pil_img.size,\n",
    "#                            Image.AFFINE, (1, 0, 0, level, 1, 0),\n",
    "#                            resample=Image.BILINEAR)\n",
    "\n",
    "\n",
    "# def translate_x(pil_img, level):\n",
    "#     level = int_parameter(sample_level(level), pil_img.size[0] / 3)\n",
    "#     if np.random.random() > 0.5:\n",
    "#         level = -level\n",
    "#     return pil_img.transform(pil_img.size,\n",
    "#                            Image.AFFINE, (1, 0, level, 0, 1, 0),\n",
    "#                            resample=Image.BILINEAR)\n",
    "\n",
    "\n",
    "# def translate_y(pil_img, level):\n",
    "#     level = int_parameter(sample_level(level), pil_img.size[0] / 3)\n",
    "#     if np.random.random() > 0.5:\n",
    "#         level = -level\n",
    "#     return pil_img.transform(pil_img.size,\n",
    "#                            Image.AFFINE, (1, 0, 0, 0, 1, level),\n",
    "#                            resample=Image.BILINEAR)\n",
    "\n",
    "\n",
    "# # operation that overlaps with ImageNet-C's test set\n",
    "# def color(pil_img, level):\n",
    "#     level = float_parameter(sample_level(level), 1.8) + 0.1\n",
    "#     return ImageEnhance.Color(pil_img).enhance(level)\n",
    "\n",
    "\n",
    "# # operation that overlaps with ImageNet-C's test set\n",
    "# def contrast(pil_img, level):\n",
    "#     level = float_parameter(sample_level(level), 1.8) + 0.1\n",
    "#     return ImageEnhance.Contrast(pil_img).enhance(level)\n",
    "\n",
    "\n",
    "# # operation that overlaps with ImageNet-C's test set\n",
    "# def brightness(pil_img, level):\n",
    "#     level = float_parameter(sample_level(level), 1.8) + 0.1\n",
    "#     return ImageEnhance.Brightness(pil_img).enhance(level)\n",
    "\n",
    "\n",
    "# # operation that overlaps with ImageNet-C's test set\n",
    "# def sharpness(pil_img, level):\n",
    "#     level = float_parameter(sample_level(level), 1.8) + 0.1\n",
    "#     return ImageEnhance.Sharpness(pil_img).enhance(level)\n",
    "\n",
    "\n",
    "# augmentations = [\n",
    "#     autocontrast, equalize, posterize, solarize, \n",
    "#     rotate, shear_x, shear_y,\n",
    "#     translate_x, translate_y\n",
    "# ]\n",
    "\n",
    "# augmentations_all = [\n",
    "#     autocontrast, equalize, posterize, solarize, \n",
    "#     rotate, shear_x, shear_y,\n",
    "#     translate_x, translate_y, \n",
    "#     color, contrast, brightness, sharpness\n",
    "# ]\n",
    "\n",
    "# def normalize(image):\n",
    "#     \"\"\"Normalize input image channel-wise to zero mean and unit variance.\"\"\"\n",
    "#     return image - 127\n",
    "\n",
    "# def apply_op(image, op, severity):\n",
    "#     #   image = np.clip(image, 0, 255)\n",
    "\n",
    "#     image = image * 255\n",
    "#     image = image.astype(np.uint8)\n",
    "    \n",
    "#     pil_img = Image.fromarray(image)  # Convert to PIL.Image\n",
    "#     pil_img = op(pil_img, severity)\n",
    "\n",
    "    \n",
    "#     return np.asarray(pil_img)\n",
    "\n",
    "# def augment_and_mix(image, severity=3, width=3, depth=-1, alpha=1.):\n",
    "#     \"\"\"Perform AugMix augmentations and compute mixture.\n",
    "#     Args:\n",
    "#     image: Raw input image as float32 np.ndarray of shape (h, w, c)\n",
    "#     severity: Severity of underlying augmentation operators (between 1 to 10).\n",
    "#     width: Width of augmentation chain\n",
    "#     depth: Depth of augmentation chain. -1 enables stochastic depth uniformly\n",
    "#       from [1, 3]\n",
    "#     alpha: Probability coefficient for Beta and Dirichlet distributions.\n",
    "#     Returns:\n",
    "#     mixed: Augmented and mixed image.\n",
    "#     \"\"\"\n",
    "#     ws = np.float32(\n",
    "#       np.random.dirichlet([alpha] * width))\n",
    "#     m = np.float32(np.random.beta(alpha, alpha))\n",
    "\n",
    "#     mix = np.zeros_like(image).astype(np.float32)\n",
    "#     for i in range(width):\n",
    "#         image_aug = image.copy()\n",
    "#         depth = depth if depth > 0 else np.random.randint(1, 4)\n",
    "#         for _ in range(depth):\n",
    "#             op = np.random.choice(augmentations)\n",
    "#             image_aug = apply_op(image_aug, op, severity)\n",
    "#         # Preprocessing commutes since all coefficients are convex\n",
    "#         mix += ws[i] * image_aug\n",
    "#         # mix += ws[i] * normalize(image_aug)\n",
    "\n",
    "#     # mixed = (1 - m) * image + m * mix\n",
    "#     mixed = m * image + (1 - m) * mix\n",
    "#     # mixed = (1 - m) * normalize(image) + m * mix\n",
    "\n",
    "    \n",
    "#     return mixed  / 255\n",
    "\n",
    "\n",
    "# class RandomAugMix(ImageOnlyTransform):\n",
    "\n",
    "#     def __init__(self, severity=3, width=3, depth=-1, alpha=1., always_apply=False, p=0.5):\n",
    "#         super().__init__(always_apply, p)\n",
    "#         self.severity = severity\n",
    "#         self.width = width\n",
    "#         self.depth = depth\n",
    "#         self.alpha = alpha\n",
    "\n",
    "#     def apply(self, image, **params):\n",
    "#         image = augment_and_mix(\n",
    "#             image,\n",
    "#             self.severity,\n",
    "#             self.width,\n",
    "#             self.depth,\n",
    "#             self.alpha\n",
    "#         )\n",
    "#         return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# severity=3, width=3, alpha=1., p=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = albumentations.Compose([\n",
    "    \n",
    "    RandomAugMix(severity=3, width=3, alpha=0.5,p=1),\n",
    "    \n",
    "    # albumentations.CenterCrop(p=1, height=300, width=300),\n",
    "    # albumentations.RandomRotate90,\n",
    "    ToTensorV2(),\n",
    "   \n",
    "])\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "train_dataset = CustomDataLoader(data_dir='/opt/ml/segmentation/input/data/train.json', mode='train', transform=transforms_train)\n",
    "\n",
    "# data_loader\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=12,\n",
    "    num_workers=4,\n",
    "    pin_memory=use_cuda,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "select_batch = 3\n",
    "\n",
    "if not (0 <= select_batch < len(train_loader)):\n",
    "    raise Exception(\"select_batch index error\")\n",
    "\n",
    "\n",
    "for i, (imgs, masks, image_infos) in enumerate(train_loader):\n",
    "\n",
    "    category_and_rgb = [[category, (r,g,b)] for idx, (category, r, g, b) in enumerate(class_colormap.values)]\n",
    "    legend_elements = [Patch(facecolor=webcolors.rgb_to_hex(rgb), \n",
    "                            edgecolor=webcolors.rgb_to_hex(rgb), \n",
    "                            label=category) for category, rgb in category_and_rgb]\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=6, ncols=4, figsize=(20, 30))\n",
    "    # train_loader의 output 결과(image 및 mask) 확인\n",
    "    for i in range(len(imgs)):\n",
    "\n",
    "        temp_image_infos = image_infos[i]\n",
    "        temp_images = imgs[i]\n",
    "        temp_masks = masks[i]\n",
    "\n",
    "        # ax[int(i//2),0 + (i%2)*2].imshow(temp_images)\n",
    "        # ax[int(i//2),0 + (i%2)*2].grid(False)\n",
    "        # ax[int(i//2),0 + (i%2)*2].set_title(\"{}\".format([category_names[int(i)] for i in list(np.unique(temp_masks))]), fontsize = 10)\n",
    "        # ax[int(i//2),0 + (i%2)*2].set_xlabel(temp_image_infos['file_name'])\n",
    "\n",
    "        # ax[int(i//2),1 + (i%2)*2].imshow(label_to_color_image(temp_masks.detach().cpu().numpy()))\n",
    "        # ax[int(i//2),1 + (i%2)*2].grid(False)\n",
    "        # #ax[int(i//2),1 + (i%2)*2].set_title(\"{}\".format([{int(i),category_names[int(i)]} for i in list(np.unique(temp_masks))], fontsize = 5))\n",
    "        # if (i%2)*2 == 2:\n",
    "        #     ax[int(i//2),1 + (i%2)*2].legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)\n",
    "            \n",
    "        \n",
    "        ax[int(i//2),0 + (i%2)*2].imshow(temp_images.permute([1,2,0]))\n",
    "        ax[int(i//2),0 + (i%2)*2].grid(False)\n",
    "        ax[int(i//2),0 + (i%2)*2].set_title(\"{}\".format([category_names[int(i)] for i in list(np.unique(temp_masks))]), fontsize = 10)\n",
    "        ax[int(i//2),0 + (i%2)*2].set_xlabel(temp_image_infos['file_name'])\n",
    "\n",
    "        ax[int(i//2),1 + (i%2)*2].imshow(label_to_color_image(temp_masks.detach().cpu().numpy()))\n",
    "        ax[int(i//2),1 + (i%2)*2].grid(False)\n",
    "        #ax[int(i//2),1 + (i%2)*2].set_title(\"{}\".format([{int(i),category_names[int(i)]} for i in list(np.unique(temp_masks))], fontsize = 5))\n",
    "        if (i%2)*2 == 2:\n",
    "            ax[int(i//2),1 + (i%2)*2].legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)\n",
    "    break\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 원본 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = albumentations.Compose([\n",
    "    # RandomAugMix(severity=3, width=3, p=1.),\n",
    "    # albumentations.CenterCrop(p=1, height=300, width=300),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "train_dataset = CustomDataLoader(data_dir='/opt/ml/segmentation/input/data/train.json', mode='train', transform=transforms_train)\n",
    "\n",
    "# data_loader\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=12,\n",
    "    num_workers=4,\n",
    "    # shuffle=True,\n",
    "    pin_memory=use_cuda,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "select_batch = 3\n",
    "\n",
    "if not (0 <= select_batch < len(train_loader)):\n",
    "    raise Exception(\"select_batch index error\")\n",
    "\n",
    "\n",
    "for i, (imgs, masks, image_infos) in enumerate(train_loader):\n",
    "\n",
    "    category_and_rgb = [[category, (r,g,b)] for idx, (category, r, g, b) in enumerate(class_colormap.values)]\n",
    "    legend_elements = [Patch(facecolor=webcolors.rgb_to_hex(rgb), \n",
    "                            edgecolor=webcolors.rgb_to_hex(rgb), \n",
    "                            label=category) for category, rgb in category_and_rgb]\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=6, ncols=4, figsize=(20, 30))\n",
    "    # train_loader의 output 결과(image 및 mask) 확인\n",
    "    for i in range(len(imgs)):\n",
    "        temp_image_infos = image_infos[i]\n",
    "        temp_images = imgs[i] \n",
    "        temp_masks = masks[i]\n",
    "\n",
    "        temp_images = torch.from_numpy(temp_images)\n",
    "        temp_masks = torch.from_numpy(temp_masks)\n",
    "\n",
    "        \n",
    "        ax[int(i//2),0 + (i%2)*2].imshow(temp_images)\n",
    "        ax[int(i//2),0 + (i%2)*2].grid(False)\n",
    "        ax[int(i//2),0 + (i%2)*2].set_title(\"{}\".format([category_names[int(i)] for i in list(np.unique(temp_masks))]), fontsize = 10)\n",
    "        ax[int(i//2),0 + (i%2)*2].set_xlabel(temp_image_infos['file_name'])\n",
    "\n",
    "        ax[int(i//2),1 + (i%2)*2].imshow(label_to_color_image(temp_masks.detach().cpu().numpy()))\n",
    "        ax[int(i//2),1 + (i%2)*2].grid(False)\n",
    "        #ax[int(i//2),1 + (i%2)*2].set_title(\"{}\".format([{int(i),category_names[int(i)]} for i in list(np.unique(temp_masks))], fontsize = 5))\n",
    "        if (i%2)*2 == 2:\n",
    "            ax[int(i//2),1 + (i%2)*2].legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)\n",
    "            \n",
    "        \n",
    "        # ax[int(i//2),0 + (i%2)*2].imshow(temp_images.permute([1,2,0]))\n",
    "        # ax[int(i//2),0 + (i%2)*2].grid(False)\n",
    "        # ax[int(i//2),0 + (i%2)*2].set_title(\"{}\".format([category_names[int(i)] for i in list(np.unique(temp_masks))]), fontsize = 10)\n",
    "        # ax[int(i//2),0 + (i%2)*2].set_xlabel(temp_image_infos['file_name'])\n",
    "\n",
    "        # ax[int(i//2),1 + (i%2)*2].imshow(label_to_color_image(temp_masks.detach().cpu().numpy()))\n",
    "        # ax[int(i//2),1 + (i%2)*2].grid(False)\n",
    "        # #ax[int(i//2),1 + (i%2)*2].set_title(\"{}\".format([{int(i),category_names[int(i)]} for i in list(np.unique(temp_masks))], fontsize = 5))\n",
    "        # if (i%2)*2 == 2:\n",
    "        #     ax[int(i//2),1 + (i%2)*2].legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)\n",
    "    break\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d36e052b391be8c28b05838ade06426769a29575d5fe21a7bc69c7dec0c04c06"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('segmentation': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
